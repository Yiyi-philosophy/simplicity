---
title : 'conda, pip, docker: source'
image : '2025-02-19-R1/image-20250219182712528.png'
tag : toolSSH
---

# Ssh 

<!--more-->

常规连接

- 通过ssh -p 10022 xxx@yyyy 连接到跳板机，
- 再ssh root@nv-h100-030 连接到h100 服务器，
- 而 h100 服务器上配置localhost:11434 ollama 服务 
- 设置端口转发使得本机:localhost:51434 开放ollama

```shell
ssh -L 0.0.0.0:51434:localhost:11434 -J xxx@yyyy:10022 root@nv-h100-030
```

设置端口转发

```shell
ssh -p 10022 xxx@yyyy -R 55557:localhost:7890
export https_proxy=http://localhost:55657
export http_proxy=http://localhost:55657
ssh root@nv-h100-030 -R 55557:localhost:55657
export https_proxy=http://localhost:55657
export http_proxy=http://localhost:55657
```



直接连接：
`ssh -J xxx@yyyy:10022 root@nv-h100-030` 

传输文件：

`rsync -avzP -e 'ssh -J xxx@yyyy:10022' Qwen3-30B-A3B/ root@nv-h100-030:/home/zzzz/`

---

通过dnf 管理包文件

`dnf install -y nvtop`

---

docker 打包环境传输
`docker save  vllm/vllm-openai:v0.8.5.post1 -o vllm-image.tar`

`docker load -i vllm-image.tar`



## fish

config file: `~/.config/fish/config.fish`

defaut history file: `.local/share/fish/fish_history`

change to new path: add `set -Ux fish_history /Files/fish` to config file